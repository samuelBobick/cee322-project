{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f3566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-reload modules when they change (no need to restart kernel)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from IPython.display import Image, display\n",
    "\n",
    "FINAL_PROJECT_DIR = \"/Users/sam/Desktop/cee322/final\"\n",
    "\n",
    "if FINAL_PROJECT_DIR not in sys.path:\n",
    "    sys.path.insert(0, FINAL_PROJECT_DIR)\n",
    "\n",
    "from src.state import DataEngState\n",
    "from src.agent import create_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c0a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "langsmith_api_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "langsmith_tracing = os.getenv(\"LANGSMITH_TRACING\")\n",
    "\n",
    "if not api_key:\n",
    "    raise RuntimeError(\n",
    "        \"OPENAI_API_KEY environment variable is not set; please configure it to run this example.\"\n",
    "    )\n",
    "\n",
    "chat_model = init_chat_model(model=\"gpt-4o-mini\", api_key=api_key)\n",
    "\n",
    "DATA_FILEPATH = \"/Users/sam/Desktop/cee322/final/data/hard.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd02931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent\n",
    "clean_impute_agent = create_agent(chat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c4996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the 2-node structure\n",
    "display(Image(clean_impute_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_clean_impute_state: DataEngState = {\n",
    "    \"filepath\": DATA_FILEPATH,\n",
    "}\n",
    "\n",
    "final_clean_impute_state = clean_impute_agent.invoke(initial_clean_impute_state)\n",
    "print(\"\\n=== 4-NODE AGENT COMPLETE (clean -> reflect_clean -> impute -> reflect_impute) ===\")\n",
    "print(\"Errors:\", final_clean_impute_state.get(\"errors\"))\n",
    "if final_clean_impute_state.get(\"data\") is not None:\n",
    "    data = final_clean_impute_state[\"data\"]\n",
    "    print(f\"Final data shape: {len(data)} rows × {len(data.columns)} columns\")\n",
    "    print(f\"Missing values remaining: {data.isna().sum().sum()}\")\n",
    "    print(f\"\\nCleaning records ({len(final_clean_impute_state.get('cleaning_records', []))}):\")\n",
    "    for record in final_clean_impute_state.get(\"cleaning_records\", []):\n",
    "        print(f\"  - {record}\")\n",
    "    print(f\"\\nImputation records ({len(final_clean_impute_state.get('imputation_records', []))}):\")\n",
    "    for record in final_clean_impute_state.get(\"imputation_records\", [])[:5]:  # Show first 5\n",
    "        print(f\"  - {record}\")\n",
    "    if len(final_clean_impute_state.get(\"imputation_records\", [])) > 5:\n",
    "        print(f\"  ... and {len(final_clean_impute_state.get('imputation_records', [])) - 5} more\")\n",
    "    print(f\"\\nMissing info: {len(final_clean_impute_state.get('missing_info', {}))} columns with missing values\")\n",
    "    print(f\"Summary stats: {len(final_clean_impute_state.get('summary_stats', {}))} numeric columns analyzed\")\n",
    "    print(f\"\\nCleaning assumptions ({len(final_clean_impute_state.get('cleaning_assumptions', {}))}):\")\n",
    "    for col, rules in final_clean_impute_state.get(\"cleaning_assumptions\", {}).items():\n",
    "        print(f\"  - {col}: {rules}\")\n",
    "    print(f\"\\nImputation assumptions ({len(final_clean_impute_state.get('imputation_assumptions', {}))}):\")\n",
    "    for col, rules in final_clean_impute_state.get(\"imputation_assumptions\", {}).items():\n",
    "        print(f\"  - {col}: {rules}\")\n",
    "    \n",
    "    # Save cleaned DataFrame to data folder\n",
    "    filepath = final_clean_impute_state.get(\"filepath\", \"\")\n",
    "    if filepath:\n",
    "        base_name = os.path.basename(filepath)\n",
    "        name_without_ext = os.path.splitext(base_name)[0]\n",
    "        data_dir = \"/Users/sam/Desktop/cee322/final/data\"\n",
    "        output_filepath = os.path.join(data_dir, f\"{name_without_ext}_cleaned.csv\")\n",
    "        \n",
    "        try:\n",
    "            os.makedirs(data_dir, exist_ok=True)\n",
    "            data.to_csv(output_filepath, index=False)\n",
    "            print(f\"\\n✓ Cleaned data saved to: {output_filepath}\")\n",
    "            print(f\"  Saved {len(data)} rows × {len(data.columns)} columns\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n⚠ Error saving cleaned data: {e}\")\n",
    "    \n",
    "    print(\"\\nNote: cleaning_assumptions and imputation_assumptions can be cached and reused in future runs for reproducibility\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f6eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hw8",
   "language": "python",
   "name": "hw8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
